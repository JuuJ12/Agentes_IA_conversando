import os
from autogen import ConversableAgent
from dotenv import load_dotenv
import streamlit as st
from streamlit_lottie import st_lottie
from paginas.me import load_lottiefile

load_dotenv()
animacao2 = load_lottiefile('pictures/animacao_ia2.json')
st.title('Agentes de InteligÃªncia Artificial')

with st.expander('Sobre o Projeto'):
     st.write('Esse sistema tem como objetivo mostrar como  agentes de InteligÃªncia Artificial(IA) podem conversar entre si,\
                e resolver problemas juntos. Para iniciar a conversa, vocÃª pode definir assunto da conversa.')
     
col1,col2 = st.columns([1.2,0.5], vertical_alignment='center')
with col1:
    global idioma
    idioma = st.selectbox(label='Idioma', options=['PortuguÃªs','InglÃªs','JaponÃªs','Russo','Espanhol','FrÃ¢nces','Italiano'])

    global assunto
    assunto = st.text_input(label='Assunto', help='Defina o assunto que os agentes irÃ£o gerar hipoteses e irÃ£o aplicar revisÃ£o, classificaÃ§Ã£o,evoluÃ§Ã£o,organizaÃ§Ã£o e meta-revisÃ£o para as hipoteses.',
                             placeholder=' Exemplo: Problema dos TrÃªs Corpos')
    button= st.button('Iniciar Conversa')


with col2:
    animacao = load_lottiefile('pictures/animacao_ia.json')
    
    st_lottie(animacao)

    

agente_1 = ConversableAgent(
    name='Agente-Gerador-HipÃ³teses',
    system_message=(f'VocÃª vai responder sempre em {idioma} e serÃ¡ um gerador de hipÃ³teses criativas e cientificamente embasadas sobre o tema fornecido. '),
    llm_config={
        "model": "llama3-70b-8192",
          
        "api_key": os.getenv("GROQ_API_KEY"),
        "api_type": "groq",
        "temperature":1
    },
)


agente_2 = ConversableAgent(
    name="Agente-Revisor",
    system_message=(f'VocÃª vai responder sempre em {idioma} e vai revisar criticamente as hipÃ³teses fornecidas, verificando sua novidade, correÃ§Ã£o e qualidade. '),
    llm_config={
        "model": "llama3-70b-8192",
          
        "api_key": os.getenv("GROQ_API_KEY"),
        "api_type": "groq",
        "temperature":1
    },
)

agente_3 = ConversableAgent(
    name="Agente-Classificador",
    system_message=(f'''VocÃª vai responder sempre em {idioma} e vai 
                    classificar as hipÃ³teses com base em critÃ©rios cientÃ­ficos, priorizando as mais promissoras.'''),
    llm_config={
        "model": "llama3-70b-8192",
          
        "api_key": os.getenv("GROQ_API_KEY"),
        "api_type": "groq",
        "temperature":1
    },
)


agente_4 = ConversableAgent(
    name="Agente-Evolucionador",
    system_message=(f'''VocÃª vai responder sempre em ({idioma} e vai 
                    refinar as hipÃ³teses mais bem classificadas, tornando-as mais inovadoras e viÃ¡veis.'''),
    llm_config={
        "model": "llama3-70b-8192",
          
        "api_key": os.getenv("GROQ_API_KEY"),
        "api_type": "groq",
        "temperature":1
    },
)


agente_5 = ConversableAgent(
    name="Agente-Organizador",
    system_message=(f'''VocÃª vai responder sempre em {idioma} e vai 
                    agrupar hipÃ³teses similares para facilitar a exploraÃ§Ã£o eficiente.'''),
    llm_config={
        "model": "llama3-70b-8192",
          
        "api_key": os.getenv("GROQ_API_KEY"),
        "api_type": "groq",
        "temperature":1
    },
)

agente_6 = ConversableAgent(
    name="Agente-Metarevisor",
    system_message=(f'''VocÃª vai responder sempre em {idioma} e vai 
                    analisar os feedbacks e proponha melhorias para aperfeiÃ§oar o ciclo de geraÃ§Ã£o e avaliaÃ§Ã£o de hipÃ³teses.'''),
    llm_config={
        "model": "llama3-70b-8192",
          
        "api_key": os.getenv("GROQ_API_KEY"),
        "api_type": "groq",
        "temperature":1
    },
)



def chat1(assunto):
        
        chat_result_1 = agente_1.generate_reply(messages=[{"role": "user", "content": f"Gere hipÃ³teses sobre: {assunto}"}])
        hipoteses_geradas = chat_result_1['content']
        yield f"\nğŸ§ **{agente_1.name}**\n respondeu : {hipoteses_geradas}"

        chat_result_2 = agente_2.generate_reply(messages=[{"role": "user", "content": f"Revise estas hipÃ³teses: {hipoteses_geradas}"}])
        revisao = chat_result_2['content']
        yield f"\nâœï¸**{agente_2.name}** respondeu, {revisao} "

        
        chat_result_3 = agente_3.generate_reply(messages=[{"role": "user", "content": f"Classifique as hipÃ³teses revisadas: {revisao}"}])
        classificacao = chat_result_3['content']
        yield f"\nğŸ“Š**{agente_3.name}** respondeu , {classificacao}"

        chat_result_4 = agente_4.generate_reply(messages=[{"role": "user", "content": f"Refine as hipÃ³teses mais bem classificadas: {classificacao}"}])
        refinacao = chat_result_4['content']
        yield f"\nğŸ”¬**{agente_4.name}** respondeu, {refinacao}"
        
        chat_result_5 = agente_5.generate_reply(messages=[{"role": "user", "content": f"Agrupe as hipÃ³teses similares: {refinacao}"}])
        organizacao = chat_result_5['content']
        yield f"\n ğŸ‘·â€â™‚ï¸ **{agente_5.name}** respondeu, {organizacao}"

        chat_result_6 = agente_6.generate_reply(messages=[{"role": "user", "content": f"Analise os feedbacks: {organizacao}"}])
        meta_revisao = chat_result_6['content']
        yield f"\nğŸ§**{agente_6.name}** respondeu, {meta_revisao}"

        
        


if button:
    with st.spinner('Aguarde um momento, os agentes estÃ£o batendo um papo ğŸ—£...'):
        resultado = chat1(assunto)

        for resultado in resultado:

                with st.chat_message('ai'):
                    st.write(resultado)
                    st.write("________")

