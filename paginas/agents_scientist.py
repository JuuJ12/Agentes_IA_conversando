import os
from autogen import ConversableAgent
from dotenv import load_dotenv
import streamlit as st
from streamlit_lottie import st_lottie
from paginas.me import load_lottiefile
import numpy as np
import random
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

load_dotenv()
animacao2 = load_lottiefile('pictures/animacao_ia.json')

# Inicializa√ß√£o dos valores no session_state
defaults = {
    'funcao_agente1': 'Gerador de Hip√≥teses, explorando a literatura e usando t√©cnicas como debates simulados e identifica√ß√£o iterativa de suposi√ß√µes para propor hip√≥teses de pesquisa. Escolha uma Hip√≥tese caso n√£o receba uma.',
    'funcao_agente2': 'Revisor, avaliando criticamente hip√≥teses quanto √† novidade, corre√ß√£o e qualidade, baseando-se em pesquisas na web e literatura cient√≠fica, fa√ßa sua revis√£o lembrando que ela ser√° passada para um organizador que utilizando um sistema de torneio baseado em Elo para classificar hip√≥teses com base em debates cient√≠ficos e feedbacks de revis√£o, priorizando ideias promissoras.',
    'funcao_agente3': 'Classificador, utilizando um sistema de torneio baseado em Elo para classificar hip√≥teses com base em debates cient√≠ficos e feedbacks de revis√£o, priorizando ideias promissoras, fa√ßa sua classifica√ß√£o lembrando que ela ser√° passada para um evololucionador que vai refinar as hip√≥teses mais bem classificadas ao incorporar novos insights, simplificar conceitos e explorar abordagens n√£o convencionais.',
    'funcao_agente4': 'Evolucionador,refinando as hip√≥teses mais bem classificadas ao incorporar novos insights, simplificar conceitos e explorar abordagens n√£o convencionais, fa√ßa sua refina√ß√£o lembrando que ela ser√° passada para um organizador que vai agrupar hip√≥teses com base em similaridade para gerenciar o espa√ßo de hip√≥teses e facilitar a explora√ß√£o eficiente .',
    'funcao_agente5': 'Organizador,  agrupando hip√≥teses com base em similaridade para gerenciar o espa√ßo de hip√≥teses e facilitar a explora√ß√£o eficiente, fa√£ sua organiza√ß√£o lembrando que ela ser√° passada para um meta revisor que vai sintetizar feedbacks de todas as revis√µes e torneios para identificar problemas recorrentes e orientar a melhoria do sistema, criando efetivamente um ciclo de autoaperfei√ßoamento..',
    'funcao_agente6': 'Meta Revisor,sintetizando feedbacks de todas as revis√µes e torneios para identificar problemas recorrentes e orientar a melhoria do sistema, criando efetivamente um ciclo de autoaperfei√ßoamento.',
    'modelo_agente_1': 'llama-3.3-70b-versatile',
    'modelo_agente_2': 'llama-3.3-70b-versatile',
    'modelo_agente_3': 'llama-3.3-70b-versatile',
    'modelo_agente_4': 'llama-3.3-70b-versatile',
    'modelo_agente_5': 'llama-3.3-70b-versatile',
    'modelo_agente_6': 'llama-3.3-70b-versatile',
    'modelo_agente_7': 'llama-3.3-70b-versatile',
    'idioma': 'Portugu√™s',
    'assunto': '',
    'resposta_sintetizador': "",
    'respostas_agentes': []
}

for key, value in defaults.items():
    if key not in st.session_state:
        st.session_state[key] = value

# Fun√ß√µes auxiliares
def distance(state, goal_state):
    try:
        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform([state, goal_state])
        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
        return 1 - similarity
    except Exception as e:
        print(f"Erro ao calcular a dist√¢ncia: {e}")
        return 1.0

def calculate_reward(state, goal_state):
    try:
        dist = distance(state, goal_state)
        return -dist
    except Exception as e:
        print(f"Erro ao calcular a recompensa: {e}")
        return -np.inf

q_table = {}
epsilon = 0.1

def update_q_value(state, action, reward, next_state, alpha=0.1, gamma=0.9):
    try:
        state_action = (state, action)
        if state_action not in q_table:
            q_table[state_action] = 0.0
        current_q = q_table[state_action]
        next_q_values = [q_table.get((next_state, a), 0.0) for a in range(6)]
        max_next_q = max(next_q_values) if next_q_values else 0.0
        new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)
        if not np.isnan(new_q):
            q_table[state_action] = new_q
    except Exception as e:
        print(f"Erro ao atualizar valor Q: {e}")

def get_best_action(state):
    if random.uniform(0, 1) < epsilon:
        return "Explora√ß√£o Aleat√≥ria"
    q_values = {action: q_value for (s, action), q_value in q_table.items() if s == state}
    if q_values:
        best_action = max(q_values, key=q_values.get)
        return f"A√ß√£o mais promissora no estado '{state}'"
    else:
        return "Nenhuma a√ß√£o registrada"

# UI
st.title('Agentes de Intelig√™ncia Artificial')

with st.expander('Sobre o Projeto'):
    st.write('Esse sistema tem como objetivo mostrar como agentes de Intelig√™ncia Artificial (IA) podem conversar entre si e resolver problemas juntos. Para iniciar a conversa, voc√™ pode definir assunto da conversa.')

with st.expander('Ajustando seus Agentes'):
    col1, col2 = st.columns(2)
    with col1:
        st.subheader('Fun√ß√£o dos Agentes')
        st.write('Os agentes j√° vem com fun√ß√µes definidas por√©m, voc√™ pode alterar como voc√™ quiser!')
        st.session_state.funcao_agente1 = st.text_input('Fun√ß√£o do Agente 1', help='Por padr√£o o Agente 1 √© um Gerador de Hip√≥teses.', value=st.session_state.funcao_agente1) or 'Gerador de Hip√≥teses, explorando a literatura e usando t√©cnicas como debates simulados e identifica√ß√£o iterativa de suposi√ß√µes para propor hip√≥teses de pesquisa. Escolha uma Hip√≥tese caso n√£o receba uma.'
        st.session_state.funcao_agente2 = st.text_input('Fun√ß√£o do Agente 2', help='Por padr√£o o Agente 2 √© um Revisor.', value=st.session_state.funcao_agente2) or 'Revisor, avaliando criticamente hip√≥teses quanto √† novidade, corre√ß√£o e qualidade, baseando-se em pesquisas na web e literatura cient√≠fica.'
        st.session_state.funcao_agente3 = st.text_input('Fun√ß√£o do Agente 3', help='Por padr√£o o Agente 3 √© um Classficador.', value=st.session_state.funcao_agente3) or'Classificador, utilizando um sistema de torneio baseado em Elo para classificar hip√≥teses com base em debates cient√≠ficos e feedbacks de revis√£o, priorizando ideias promissoras.'
        st.session_state.funcao_agente4 = st.text_input('Fun√ß√£o do Agente 4', help='Por padr√£o o Agente 4 √© um  Evolucionador.', value=st.session_state.funcao_agente4) or 'Evolucionador,refinando as hip√≥teses mais bem classificadas ao incorporar novos insights, simplificar conceitos e explorar abordagens n√£o convencionais.'
        st.session_state.funcao_agente5 = st.text_input('Fun√ß√£o do Agente 5', help='Por padr√£o o Agente 5 √© um  Organizador.', value=st.session_state.funcao_agente5) or 'Organizador,  agrupando hip√≥teses com base em similaridade para gerenciar o espa√ßo de hip√≥teses e facilitar a explora√ß√£o eficiente.'
        st.session_state.funcao_agente6 = st.text_input('Fun√ß√£o do Agente 6', help='Por padr√£o o Agente 6 √© um Meta Revisor.', value=st.session_state.funcao_agente6) or 'Meta Revisor,sintetizando feedbacks de todas as revis√µes e torneios para identificar problemas recorrentes e orientar a melhoria do sistema, criando efetivamente um ciclo de autoaperfei√ßoamento.'
    with col2:
        st.subheader('Modelos de IA')
        st.write('Por padr√£o os Agentes j√° vem com o modelo llama-3.3-70b-versatile.')
        modelos = ['llama-3.3-70b-versatile', 'gemma2-9b-it', 'mistral-saba-24b']
        for i in range(1, 8):
            key = f'modelo_agente_{i}'
            st.session_state[key] = st.selectbox(f'Modelo do Agente {i if i < 7 else "Sintetizador"}', modelos, index=modelos.index(st.session_state[key]))

col1, col2 = st.columns([1.2, 0.5])
with col1:
    st.session_state.idioma = st.selectbox('Idioma', ['Portugu√™s', 'Ingl√™s', 'Japon√™s', 'Russo', 'Espanhol', 'Fr√¢nces', 'Italiano'], index=['Portugu√™s', 'Ingl√™s', 'Japon√™s', 'Russo', 'Espanhol', 'Fr√¢nces', 'Italiano'].index(st.session_state.idioma))
    st.session_state.assunto = st.text_input('Assunto',  help='Escreva o que voc√™ deseja, uma duvida, um problema, qualquer coisa !',value=st.session_state.assunto)
    button = st.button('Iniciar Conversa')

with col2:
    st_lottie(animacao2)

# Cria√ß√£o dos agentes
def criar_agente(nome, funcao, modelo):
    return ConversableAgent(
        name=nome,
        system_message=(f'Voc√™ vai responder sempre em {st.session_state.idioma}, sempre vai atacar e tentar resolver o problema e sua fun√ß√£o √© {funcao}.'),
        llm_config={
            "model": modelo,
            "api_key": os.getenv("GROQ_API_KEY"),
            "api_type": "groq",
            "temperature": 0
        }
    )

agentes = [criar_agente(f'Agente-{i+1}', st.session_state[f'funcao_agente{i+1}'], st.session_state[f'modelo_agente_{i+1}']) for i in range(6)]

agente_7 = ConversableAgent(
    name="Agente-7-Sintetizador",
    system_message=(f'''Voc√™ vai responder sempre em {st.session_state.idioma}. Sua fun√ß√£o ser√°:
        1. Ler todas as solu√ß√µes finais dos debatedores.
        2. Consolidar uma solu√ß√£o final abrangente.
        3. Elencar as melhores ideias dos debatedores.
        4. Finalizar com uma conclus√£o.
        5. Reescrever o texto inicial.'''),
    llm_config={
        "model": st.session_state.modelo_agente_7,
        "api_key": os.getenv("GROQ_API_KEY"),
        "api_type": "groq",
        "temperature": 0
    }
)

# Chat
def chat(assunto):
    state = "inicio"
    previous_response = assunto
    respostas = []

    for idx, agente in enumerate(agentes):
        chat_result = agente.generate_reply(messages=[{"role": "user", "content": previous_response}])
        resposta = chat_result['content']
        next_state = f"debate-{idx+1}"
        reward = calculate_reward(resposta, "objetivo")
        update_q_value(state, resposta, reward, next_state)
        best_action = get_best_action(state)

        respostas.append(resposta)
        previous_response = resposta

        # Salvando a resposta no session_state
        st.session_state.respostas_agentes.append({
            "modelo": agente.llm_config.config_list[0]['model'],
            "nome": agente.name,
            "resposta": resposta,
            "acao": best_action
        })

        yield f"\nü§ñ **{agente.name}** respondeu: {resposta}"
        state = next_state

    resposta_sintetizada = agente_7.generate_reply(messages=[{"role": "user", "content": " ".join(respostas)}])
    st.session_state.resposta_sintetizador = resposta_sintetizada['content']
    yield f"\nüìù **{agente_7.name}** sintetizou: {resposta_sintetizada['content']}"


# Execu√ß√£o
if button:
    # Resetar respostas antigas
    st.session_state.respostas_agentes = []
    st.session_state.resposta_sintetizador = ""

    with st.spinner('Aguarde um momento, os agentes est√£o batendo um papo üó£...'):
        for resultado in chat(st.session_state.assunto):
            with st.chat_message('ai'):
                st.write(resultado)

if 'respostas_agentes' in st.session_state and st.session_state.respostas_agentes:
    st.subheader("üí¨ Respostas anteriores dos agentes:")
    for resposta in st.session_state.respostas_agentes:
        st.write(f"**{resposta['nome']}** (modelo: {resposta['modelo']})")
        st.write(f"üó£ Resposta: {resposta['resposta']}")
        st.markdown("---")


if 'resposta_sintetizador' in st.session_state and st.session_state.resposta_sintetizador:
    st.subheader("üìù Resposta do Agente Sintetizador:")
    st.write(st.session_state.resposta_sintetizador)

